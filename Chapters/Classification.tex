

\section{Overview}
While classification is only a single part of the CloudAssure system, all
operations hinge off its categorization decision. Classification is currently an
very active area of research \autocite{Zhang2000}, expecially with respect to
internet documents. Classification is a branch of machine learning which
attempts to predict the underlying topic, or classification of a given document.
As a discipline under machine learning it's helpful to describe machine learning
at a high level, before describing the classification techniqus evaluated and
finally implemented in CloudAssure

\section{Machine Learning with Respect to Classification}
Machine Learning can be described as a mathematical model which reverses a human
processes \autocite{Bishop2009}. In the area of classification this is
a straightforward description. A given document is composed of words which
intend to presuade or inform the reader. Thus, the documents words are related
by some list of topics \autocite{Blei2009}. LDA supposes that documents are
written in the following fashion:
\begin{enumerate}
    \item The author has a finite set of lists. Each list contains a vocabulary
        for a given topic.
    \item The author chooses to start writing a document.
    \item The author rolls a die which chooses a topic list.
    \item The author rolls the die again which chooses a word from the selected
        topic list.
    \item The author writes down the word.
    \item The author continues roll the die until the document is of sufficient
        length.
    \item Once the document is complete, the author destroys the topic lists.
\end{enumerate}
%TODO Insert the pretty colored document picture here.
Now given any document, what are the topics contained in it? The original topic
lists were destroyed, so LDA proposes a method to recreate them. Thus reversing
the process of writing a document.

All classification methods use some algorithm which assumes a specific
distribution to the document with the intent of extracting some unobservable
property. During the course of CloudAssure, we looked at a number of techniques
including LDA, Neural Nets, Bayesian Inference, Decision Trees, and finally,
Support Vector Machines.

\subsection{Latent Dirichlet Allocation}
In ``Probabilistic Topic Models'', Blei describes the Latent Dirichlet
Allocation and its probabilistic approach to topic prediction
\autocite{Blei2012}. 
\autocite{RadimRehurek2010}

\subsection{Neural Nets}
\autocite{Zhang2000}
\autocite{Merkl}

\subsection{Bayesian Inference}
\autocite{Bishop2009}

\subsection{Decision Trees}
\autocite{Segaran2008}
\autocite{Russell2008}

\subsection{Support Vector Machines}
\autocite{Chang2011}
The Classification System thusly
needs to be properly trained for the best performance. The Classifier has two
possible algorithms available. Depending on the implementor's dataset, one will
offer more accurate results.

The Classifier, should provide a statically significant improvemnet over simply
guessing the category. For instance, if the dataset contains 4 categories, then
random chance will classify a document in the correct category 25\% of the time.
To be useful, our classifier must do more accurate job than this. With our
demonstration dataset, the Bayesian classifier scored 82.54\% accurate,
and the Decision Tree classifier scored 86.87\% accurate.

\section{Implementation}
Our implementation is divided into two parts: A Direct Implementation, and
a second implementation utilizing nltk
	- What nltk actually does
	- Compare initial naïve version with the high performance nltk version
	- Walk through how the implementation works.
    \autocite{University}
\subsection{Direct Implementation}
Performance Problems \autocite{Graham-Cummings2005}
\autocite{Denoyer2004}
\subsection{NLTK Implementation}

\section{Bayesian Classifier}
	- Bayasian
		? How "independence" makes the equation easier

\section{Decision Tree Classifier}
A decision tree classifier is 
\begin{algorithmic}
    \If{ contains(professor) == False}
        \If{ contains(course) == False}
            \If{ contains(syllabus) == False}
                \If{ contains(faculty) == False} 
                    \Return{ u'Student'}
                \EndIf
                 \If{ contains(faculty) == True} 
                    \Return{ u'Student'}
                \EndIf
                \If{ contains(syllabus) == True}
                        \If{ contains(faculty) == False} 
                            \Return{ u'Course'}
                        \EndIf
                        \If{ contains(faculty) == True} 
                            \Return{ u'Faculty'}
                        \EndIf
                        \If{ contains(course) == True}
                            \If{ contains(interests) == False}
                                \If{ contains(resume) == False} 
                                        \Return{ u'Course'}
                                \EndIf
                            \EndIf
                        \EndIf
                    \EndIf
                \EndIf
            \EndIf
        \EndIf
\end{algorithmic}

\section{Training the Classifiers}
\subsection{Choosing a DataSet}

\subsection{Implementor Workflow}
	- Describe the IT implementor workflow
		? Obtain sufficiently classified data
		? Build the database
			§ Document selection needs to be done carefully. Adding poor data will decrease the precision of the qualifier
		? Build the model (Choose an algorithm) 
			§ Tree model for 3695 documents took 75 minutes (0.868741542625 accurate)
			§ Bayes model for 3695 documents took 3 minutes (0.8254 accurate)
		? Use the classifier and the model to classify new documents

\subsection{Security Concerns}
It is critically important that the .plk file be stored in a secure place, or be
cryptographically secured and verified prior to each load. The .plk file if
manipulated by a maleficent agent can be used to subvert the trust system and
classify data into anyfor category of the agent's choosing.  


